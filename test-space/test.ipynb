{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import nltk \n",
    "from nltk import bigrams, FreqDist, ConditionalFreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/codespace/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "\n",
    "## Keep your training documents in a folder named 'data'\n",
    "input_data_dir = \"data\"\n",
    "\n",
    "# String of punctuation without the full stop\n",
    "punctuation = string.punctuation.replace('.', '')  # Retain the full stop\n",
    "\n",
    "def is_hidden(filepath):\n",
    "    return os.path.basename(filepath).startswith('.')\n",
    "\n",
    "text_data=\"\"\n",
    "for filename in os.listdir(input_data_dir):\n",
    "    filepath = os.path.join(input_data_dir, filename)\n",
    "    if not is_hidden(filepath):\n",
    "        with open(filepath) as infile:\n",
    "            for line in infile:\n",
    "                if line.strip():  # Check if line is not just whitespace\n",
    "                    # Remove all punctuation except full stops\n",
    "                    for char in punctuation:\n",
    "                        line = line.replace(char, '')\n",
    "                    text_data += line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text into words\n",
    "# Lowercasing for consistency\n",
    "words = nltk.word_tokenize(text_data.lower())\n",
    "\n",
    "# Generate bigrams\n",
    "bi_grams = list(bigrams(words))\n",
    "\n",
    "# Calculate frequency distribution for each bigram\n",
    "bi_gram_freq_dist = FreqDist(bi_grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "# Print the first five elements of the dictionary\n",
    "first_five_items = list(islice(bi_gram_freq_dist.items(), 5))\n",
    "for item in first_five_items:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute conditional frequency distribution of bigrams\n",
    "bi_gram_freq = ConditionalFreqDist(bi_grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_gram_freq['natural']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "topk=3\n",
    "# Create a dictionary to hold the top topk bigrams for each first word\n",
    "top_bigrams_per_first_word = {}\n",
    "\n",
    "# Iterate over the bigram frequency distribution\n",
    "for (first_word, second_word), freq in bi_gram_freq_dist.items():\n",
    "    # Initialize an empty heap for the first_word if it doesn't exist\n",
    "    if first_word not in top_bigrams_per_first_word:\n",
    "        top_bigrams_per_first_word[first_word] = []\n",
    "\n",
    "    # Add to the heap and maintain top topk\n",
    "    heapq.heappush(top_bigrams_per_first_word[first_word],\n",
    "                   (freq, second_word))\n",
    "    if len(top_bigrams_per_first_word[first_word]) > topk:\n",
    "        heapq.heappop(top_bigrams_per_first_word[first_word])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_bigrams_per_first_word['natural']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the heap to a simple list for each first word\n",
    "for first_word in top_bigrams_per_first_word:\n",
    "    sorted_bigrams = sorted(\n",
    "        top_bigrams_per_first_word[first_word], reverse=True)\n",
    "    top_bigrams_list = []\n",
    "    for freq, second_word in sorted_bigrams:\n",
    "        top_bigrams_list.append(second_word)\n",
    "    top_bigrams_per_first_word[first_word] = top_bigrams_list\n",
    "\n",
    "# Use these filtered bigrams to create a ConditionalFreqDist\n",
    "filtered_bi_grams = []\n",
    "for first_word in top_bigrams_per_first_word:\n",
    "    for second_word in top_bigrams_per_first_word[first_word]:\n",
    "        filtered_bi_grams.append((first_word, second_word))\n",
    "\n",
    "bi_gram_freq = ConditionalFreqDist(filtered_bi_grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence(word, num_words):\n",
    "    word =word.lower()\n",
    "    for _ in range(num_words):\n",
    "        print(word, end=' ')\n",
    "        next_words = [item for item, freq in bi_gram_freq[word].items()]\n",
    "        if len(next_words) > 0:\n",
    "            # Randomly choose a next word\n",
    "            word = random.choice(next_words)\n",
    "        else:\n",
    "            break  # Break if the word has no following words\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_sentence('Asia', 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
