{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ethanchristoff/CM2603-Data_Science_Project-G20/blob/master/test-space/test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jz4ZPg08VwOy"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import nltk\n",
        "from nltk import bigrams, FreqDist, ConditionalFreqDist\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6T0dMgGcVwO0",
        "outputId": "2d5b973d-d1af-498b-a35f-48ab258a1725"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to c:\\Users\\Ethan\\Documents\\Code\n",
            "[nltk_data]     s\\CM2603-Data_Science_Project-G20\\test-\n",
            "[nltk_data]     space\\nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to c:\\Users\\Ethan\\Documents\\Co\n",
            "[nltk_data]     des\\CM2603-Data_Science_Project-G20\\test-\n",
            "[nltk_data]     space\\nltk_data...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to c:\\Users\\Ethan\\Documents\\Co\n",
            "[nltk_data]     des\\CM2603-Data_Science_Project-G20\\test-\n",
            "[nltk_data]     space\\nltk_data...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk_data_dir = os.path.join(os.getcwd(), 'nltk_data')\n",
        "if not os.path.exists(nltk_data_dir):\n",
        "    os.makedirs(nltk_data_dir)\n",
        "\n",
        "nltk.data.path.append(nltk_data_dir)\n",
        "\n",
        "nltk.download('punkt', download_dir=nltk_data_dir)\n",
        "nltk.download('wordnet', download_dir=nltk_data_dir)\n",
        "nltk.download('omw-1.4', download_dir=nltk_data_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hwxtzae-VwO1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import string\n",
        "\n",
        "## Keep your training documents in a folder named 'data'\n",
        "input_data_dir = \"data\"\n",
        "\n",
        "# String of punctuation without the full stop\n",
        "punctuation = string.punctuation.replace('.', '')  # Retain the full stop\n",
        "\n",
        "def is_hidden(filepath):\n",
        "    return os.path.basename(filepath).startswith('.')\n",
        "\n",
        "text_data=\"\"\n",
        "for filename in os.listdir(input_data_dir):\n",
        "    filepath = os.path.join(input_data_dir, filename)\n",
        "    if not is_hidden(filepath):\n",
        "        with open(filepath) as infile:\n",
        "            for line in infile:\n",
        "                if line.strip():  # Check if line is not just whitespace\n",
        "                    # Remove all punctuation except full stops\n",
        "                    for char in punctuation:\n",
        "                        line = line.replace(char, '')\n",
        "                    text_data += line"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "83Bzycv3VwO1",
        "outputId": "c2bc5c7d-455f-4350-b071-9c65eebd21fe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8441834"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(text_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0u7HIEqqVwO1",
        "outputId": "39aa778b-106b-4bc7-b3d5-b04692f9fda9"
      },
      "outputs": [
        {
          "ename": "LookupError",
          "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\Ethan/nltk_data'\n    - 'c:\\\\Users\\\\Ethan\\\\Documents\\\\Codes\\\\.venv\\\\nltk_data'\n    - 'c:\\\\Users\\\\Ethan\\\\Documents\\\\Codes\\\\.venv\\\\share\\\\nltk_data'\n    - 'c:\\\\Users\\\\Ethan\\\\Documents\\\\Codes\\\\.venv\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Ethan\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - 'c:\\\\Users\\\\Ethan\\\\Documents\\\\Codes\\\\CM2603-Data_Science_Project-G20\\\\test-space\\\\nltk_data'\n    - 'c:\\\\Users\\\\Ethan\\\\Documents\\\\Codes\\\\CM2603-Data_Science_Project-G20\\\\test-space\\\\nltk_data'\n**********************************************************************\n",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m words \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Generate bigrams\u001b[39;00m\n\u001b[0;32m      4\u001b[0m bi_grams \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(bigrams(words))\n",
            "File \u001b[1;32mc:\\Users\\Ethan\\Documents\\Codes\\.venv\\Lib\\site-packages\\nltk\\tokenize\\__init__.py:142\u001b[0m, in \u001b[0;36mword_tokenize\u001b[1;34m(text, language, preserve_line)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mword_tokenize\u001b[39m(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m, preserve_line\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    128\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;124;03m    Return a tokenized copy of *text*,\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;124;03m    using NLTK's recommended word tokenizer\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;124;03m    :type preserve_line: bool\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 142\u001b[0m     sentences \u001b[38;5;241m=\u001b[39m [text] \u001b[38;5;28;01mif\u001b[39;00m preserve_line \u001b[38;5;28;01melse\u001b[39;00m \u001b[43msent_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m    144\u001b[0m         token \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m sentences \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m _treebank_word_tokenizer\u001b[38;5;241m.\u001b[39mtokenize(sent)\n\u001b[0;32m    145\u001b[0m     ]\n",
            "File \u001b[1;32mc:\\Users\\Ethan\\Documents\\Codes\\.venv\\Lib\\site-packages\\nltk\\tokenize\\__init__.py:119\u001b[0m, in \u001b[0;36msent_tokenize\u001b[1;34m(text, language)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msent_tokenize\u001b[39m(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    110\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;124;03m    Return a sentence-tokenized copy of *text*,\u001b[39;00m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;124;03m    using NLTK's recommended sentence tokenizer\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;124;03m    :param language: the model name in the Punkt corpus\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 119\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43m_get_punkt_tokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mtokenize(text)\n",
            "File \u001b[1;32mc:\\Users\\Ethan\\Documents\\Codes\\.venv\\Lib\\site-packages\\nltk\\tokenize\\__init__.py:105\u001b[0m, in \u001b[0;36m_get_punkt_tokenizer\u001b[1;34m(language)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mlru_cache\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_punkt_tokenizer\u001b[39m(language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     98\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;124;03m    A constructor for the PunktTokenizer that utilizes\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;124;03m    a lru cache for performance.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;124;03m    :type language: str\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPunktTokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Ethan\\Documents\\Codes\\.venv\\Lib\\site-packages\\nltk\\tokenize\\punkt.py:1744\u001b[0m, in \u001b[0;36mPunktTokenizer.__init__\u001b[1;34m(self, lang)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m   1743\u001b[0m     PunktSentenceTokenizer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m-> 1744\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_lang\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlang\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Ethan\\Documents\\Codes\\.venv\\Lib\\site-packages\\nltk\\tokenize\\punkt.py:1749\u001b[0m, in \u001b[0;36mPunktTokenizer.load_lang\u001b[1;34m(self, lang)\u001b[0m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_lang\u001b[39m(\u001b[38;5;28mself\u001b[39m, lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m   1747\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m find\n\u001b[1;32m-> 1749\u001b[0m     lang_dir \u001b[38;5;241m=\u001b[39m \u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtokenizers/punkt_tab/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlang\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1750\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_params \u001b[38;5;241m=\u001b[39m load_punkt_params(lang_dir)\n\u001b[0;32m   1751\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lang \u001b[38;5;241m=\u001b[39m lang\n",
            "File \u001b[1;32mc:\\Users\\Ethan\\Documents\\Codes\\.venv\\Lib\\site-packages\\nltk\\data.py:579\u001b[0m, in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    577\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[0;32m    578\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 579\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
            "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\Ethan/nltk_data'\n    - 'c:\\\\Users\\\\Ethan\\\\Documents\\\\Codes\\\\.venv\\\\nltk_data'\n    - 'c:\\\\Users\\\\Ethan\\\\Documents\\\\Codes\\\\.venv\\\\share\\\\nltk_data'\n    - 'c:\\\\Users\\\\Ethan\\\\Documents\\\\Codes\\\\.venv\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Ethan\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - 'c:\\\\Users\\\\Ethan\\\\Documents\\\\Codes\\\\CM2603-Data_Science_Project-G20\\\\test-space\\\\nltk_data'\n    - 'c:\\\\Users\\\\Ethan\\\\Documents\\\\Codes\\\\CM2603-Data_Science_Project-G20\\\\test-space\\\\nltk_data'\n**********************************************************************\n"
          ]
        }
      ],
      "source": [
        "words = nltk.word_tokenize(text_data.lower())\n",
        "\n",
        "# Generate bigrams\n",
        "bi_grams = list(bigrams(words))\n",
        "\n",
        "# Calculate frequency distribution for each bigram\n",
        "bi_gram_freq_dist = FreqDist(bi_grams)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7TR80UPrVwO2",
        "outputId": "a8773304-b27a-4ee4-a228-224705e987f2"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'bi_gram_freq_dist' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[8], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m islice\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Print the first five elements of the dictionary\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m first_five_items \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(islice(\u001b[43mbi_gram_freq_dist\u001b[49m\u001b[38;5;241m.\u001b[39mitems(), \u001b[38;5;241m5\u001b[39m))\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m first_five_items:\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(item)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'bi_gram_freq_dist' is not defined"
          ]
        }
      ],
      "source": [
        "from itertools import islice\n",
        "# Print the first five elements of the dictionary\n",
        "first_five_items = list(islice(bi_gram_freq_dist.items(), 5))\n",
        "for item in first_five_items:\n",
        "    print(item)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rD0rpqBkVwO2"
      },
      "outputs": [],
      "source": [
        "# Compute conditional frequency distribution of bigrams\n",
        "bi_gram_freq = ConditionalFreqDist(bi_grams)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_l56_L5VwO2"
      },
      "outputs": [],
      "source": [
        "bi_gram_freq['natural']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zVimBcCxVwO2"
      },
      "outputs": [],
      "source": [
        "import heapq\n",
        "\n",
        "topk=3\n",
        "# Create a dictionary to hold the top topk bigrams for each first word\n",
        "top_bigrams_per_first_word = {}\n",
        "\n",
        "# Iterate over the bigram frequency distribution\n",
        "for (first_word, second_word), freq in bi_gram_freq_dist.items():\n",
        "    # Initialize an empty heap for the first_word if it doesn't exist\n",
        "    if first_word not in top_bigrams_per_first_word:\n",
        "        top_bigrams_per_first_word[first_word] = []\n",
        "\n",
        "    # Add to the heap and maintain top topk\n",
        "    heapq.heappush(top_bigrams_per_first_word[first_word],\n",
        "                   (freq, second_word))\n",
        "    if len(top_bigrams_per_first_word[first_word]) > topk:\n",
        "        heapq.heappop(top_bigrams_per_first_word[first_word])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHNFqQ6_VwO2"
      },
      "outputs": [],
      "source": [
        "top_bigrams_per_first_word['natural']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZWAAbDenVwO3"
      },
      "outputs": [],
      "source": [
        "# Convert the heap to a simple list for each first word\n",
        "for first_word in top_bigrams_per_first_word:\n",
        "    sorted_bigrams = sorted(\n",
        "        top_bigrams_per_first_word[first_word], reverse=True)\n",
        "    top_bigrams_list = []\n",
        "    for freq, second_word in sorted_bigrams:\n",
        "        top_bigrams_list.append(second_word)\n",
        "    top_bigrams_per_first_word[first_word] = top_bigrams_list\n",
        "\n",
        "# Use these filtered bigrams to create a ConditionalFreqDist\n",
        "filtered_bi_grams = []\n",
        "for first_word in top_bigrams_per_first_word:\n",
        "    for second_word in top_bigrams_per_first_word[first_word]:\n",
        "        filtered_bi_grams.append((first_word, second_word))\n",
        "\n",
        "bi_gram_freq = ConditionalFreqDist(filtered_bi_grams)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJe2uprBVwO3"
      },
      "outputs": [],
      "source": [
        "def generate_sentence(word, num_words):\n",
        "    word =word.lower()\n",
        "    for _ in range(num_words):\n",
        "        print(word, end=' ')\n",
        "        next_words = [item for item, freq in bi_gram_freq[word].items()]\n",
        "        if len(next_words) > 0:\n",
        "            # Randomly choose a next word\n",
        "            word = random.choice(next_words)\n",
        "        else:\n",
        "            break  # Break if the word has no following words\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2LD8wNY9VwO3"
      },
      "outputs": [],
      "source": [
        "generate_sentence('Asia', 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBJtI9IZVwO3"
      },
      "source": [
        "# Using a simple bigram model to create a slm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TkQjkrpKVwO4"
      },
      "outputs": [],
      "source": [
        "text_string = \"\"\"Here’s an expanded version of your paragraph, extended to approximately 300–400 words:\n",
        "\n",
        "Hello, World! Everything here is beautiful, from the vibrant colors of the flowers to the serene sounds of nature. The sun casts a warm glow over the landscape, illuminating every corner with its golden rays, creating a mesmerizing display of light and shadow. As I walk through this picturesque setting, I can’t help but notice the delicate dance of butterflies fluttering from bloom to bloom, their wings painted in hues of blue, yellow, and orange. Each flower stands proudly, boasting its unique beauty, while the lush greenery provides a stunning backdrop that enhances the vivid colors of nature.\n",
        "\n",
        "Birds sing sweet melodies, adding to the symphony of life all around. Their songs echo through the air, harmonizing with the gentle rustling of leaves in the breeze. The tranquil sounds of nature serve as a soothing soundtrack, inviting moments of reflection and appreciation for the world we inhabit. Nearby, a small stream flows gracefully, its clear waters sparkling in the sunlight. The soothing sound of water trickling over smooth stones creates a sense of calm, making it a perfect spot for a peaceful retreat.\n",
        "\n",
        "Children laugh and play, their joy infectious as they run freely in the open fields. Their laughter rings like music, uplifting spirits and spreading happiness. They chase after each other, their carefree energy radiating a sense of pure delight. In this moment, time seems to stand still, allowing everyone to appreciate the simple pleasures of existence. The warm sun on my skin, the gentle breeze in my hair, and the comforting scents of earth and flowers fill my senses, grounding me in the present.\n",
        "\n",
        "Together, we create memories that last a lifetime, reminding us of the beauty and wonder that surrounds us every day. It’s in these small moments—savoring the beauty of nature, relishing laughter, and enjoying time with loved ones—that we find true happiness. As the day unfolds, I realize that life is a series of such moments, each one precious and unique. Embracing them fully helps us cultivate gratitude and a deeper connection to the world, encouraging us to cherish the simple joys and marvel at the wonders that life has to offer.\n",
        "\n",
        "Feel free to adjust any parts of the paragraph as needed!\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mE_beWTtVwO4",
        "outputId": "6e7db022-654d-403e-d04c-0d8105a169db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated words: ['world', 'everything', 'here', 'is', 'a']\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "def tokenize(text):\n",
        "    return text.replace(',', '').replace('!', '').split()\n",
        "\n",
        "def generate_bigrams(words):\n",
        "    return [(words[i].lower(), words[i + 1].lower()) for i in range(len(words) - 1)]\n",
        "\n",
        "def create_bigram_model(bigrams):\n",
        "    bigram_model = {}\n",
        "    for w1, w2 in bigrams:\n",
        "        if w1 not in bigram_model:\n",
        "            bigram_model[w1] = {}\n",
        "        bigram_model[w1][w2] = bigram_model[w1].get(w2, 0) + 1\n",
        "    for w1, next_words in bigram_model.items():\n",
        "        total_count = sum(next_words.values())\n",
        "        bigram_model[w1] = {w2: count / total_count for w2, count in next_words.items()}\n",
        "    return bigram_model\n",
        "\n",
        "def generate_words(bigram_model, start_word, count, threshold):\n",
        "    current_word = start_word.lower()\n",
        "    generated_words = []\n",
        "    for _ in range(count):\n",
        "        next_words = bigram_model.get(current_word, {})\n",
        "        valid_next_words = {word: prob for word, prob in next_words.items() if prob > threshold}\n",
        "        if not valid_next_words:\n",
        "            break\n",
        "        chosen_word = random.choices(list(valid_next_words.keys()), weights=list(valid_next_words.values()))[0]\n",
        "        generated_words.append(chosen_word)\n",
        "        current_word = chosen_word\n",
        "    return generated_words\n",
        "\n",
        "tokenized_words = tokenize(text_string)\n",
        "bigrams = generate_bigrams(tokenized_words)\n",
        "bigram_model = create_bigram_model(bigrams)\n",
        "\n",
        "start_word = \"hello\"\n",
        "threshold = 0.2\n",
        "\n",
        "new_words = generate_words(bigram_model, start_word, 10, threshold)\n",
        "print(\"Generated words:\", new_words)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "IwYkpJkGVzsL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/sample_data/california_housing_test.csv\")\n",
        "df"
      ],
      "metadata": {
        "id": "Lm5PehOdWaDH",
        "outputId": "70ca7acd-7e1d-44b5-f470-8a0a23d62aab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              "0       -122.05     37.37                27.0       3885.0           661.0   \n",
              "1       -118.30     34.26                43.0       1510.0           310.0   \n",
              "2       -117.81     33.78                27.0       3589.0           507.0   \n",
              "3       -118.36     33.82                28.0         67.0            15.0   \n",
              "4       -119.67     36.33                19.0       1241.0           244.0   \n",
              "...         ...       ...                 ...          ...             ...   \n",
              "2995    -119.86     34.42                23.0       1450.0           642.0   \n",
              "2996    -118.14     34.06                27.0       5257.0          1082.0   \n",
              "2997    -119.70     36.30                10.0        956.0           201.0   \n",
              "2998    -117.12     34.10                40.0         96.0            14.0   \n",
              "2999    -119.63     34.42                42.0       1765.0           263.0   \n",
              "\n",
              "      population  households  median_income  median_house_value  \n",
              "0         1537.0       606.0         6.6085            344700.0  \n",
              "1          809.0       277.0         3.5990            176500.0  \n",
              "2         1484.0       495.0         5.7934            270500.0  \n",
              "3           49.0        11.0         6.1359            330000.0  \n",
              "4          850.0       237.0         2.9375             81700.0  \n",
              "...          ...         ...            ...                 ...  \n",
              "2995      1258.0       607.0         1.1790            225000.0  \n",
              "2996      3496.0      1036.0         3.3906            237200.0  \n",
              "2997       693.0       220.0         2.2895             62000.0  \n",
              "2998        46.0        14.0         3.2708            162500.0  \n",
              "2999       753.0       260.0         8.5608            500001.0  \n",
              "\n",
              "[3000 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5b7cd8d8-4d3a-4a1f-8d47-3062d48eeb7b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-122.05</td>\n",
              "      <td>37.37</td>\n",
              "      <td>27.0</td>\n",
              "      <td>3885.0</td>\n",
              "      <td>661.0</td>\n",
              "      <td>1537.0</td>\n",
              "      <td>606.0</td>\n",
              "      <td>6.6085</td>\n",
              "      <td>344700.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-118.30</td>\n",
              "      <td>34.26</td>\n",
              "      <td>43.0</td>\n",
              "      <td>1510.0</td>\n",
              "      <td>310.0</td>\n",
              "      <td>809.0</td>\n",
              "      <td>277.0</td>\n",
              "      <td>3.5990</td>\n",
              "      <td>176500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-117.81</td>\n",
              "      <td>33.78</td>\n",
              "      <td>27.0</td>\n",
              "      <td>3589.0</td>\n",
              "      <td>507.0</td>\n",
              "      <td>1484.0</td>\n",
              "      <td>495.0</td>\n",
              "      <td>5.7934</td>\n",
              "      <td>270500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-118.36</td>\n",
              "      <td>33.82</td>\n",
              "      <td>28.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>6.1359</td>\n",
              "      <td>330000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-119.67</td>\n",
              "      <td>36.33</td>\n",
              "      <td>19.0</td>\n",
              "      <td>1241.0</td>\n",
              "      <td>244.0</td>\n",
              "      <td>850.0</td>\n",
              "      <td>237.0</td>\n",
              "      <td>2.9375</td>\n",
              "      <td>81700.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2995</th>\n",
              "      <td>-119.86</td>\n",
              "      <td>34.42</td>\n",
              "      <td>23.0</td>\n",
              "      <td>1450.0</td>\n",
              "      <td>642.0</td>\n",
              "      <td>1258.0</td>\n",
              "      <td>607.0</td>\n",
              "      <td>1.1790</td>\n",
              "      <td>225000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2996</th>\n",
              "      <td>-118.14</td>\n",
              "      <td>34.06</td>\n",
              "      <td>27.0</td>\n",
              "      <td>5257.0</td>\n",
              "      <td>1082.0</td>\n",
              "      <td>3496.0</td>\n",
              "      <td>1036.0</td>\n",
              "      <td>3.3906</td>\n",
              "      <td>237200.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2997</th>\n",
              "      <td>-119.70</td>\n",
              "      <td>36.30</td>\n",
              "      <td>10.0</td>\n",
              "      <td>956.0</td>\n",
              "      <td>201.0</td>\n",
              "      <td>693.0</td>\n",
              "      <td>220.0</td>\n",
              "      <td>2.2895</td>\n",
              "      <td>62000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2998</th>\n",
              "      <td>-117.12</td>\n",
              "      <td>34.10</td>\n",
              "      <td>40.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>3.2708</td>\n",
              "      <td>162500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2999</th>\n",
              "      <td>-119.63</td>\n",
              "      <td>34.42</td>\n",
              "      <td>42.0</td>\n",
              "      <td>1765.0</td>\n",
              "      <td>263.0</td>\n",
              "      <td>753.0</td>\n",
              "      <td>260.0</td>\n",
              "      <td>8.5608</td>\n",
              "      <td>500001.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3000 rows × 9 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5b7cd8d8-4d3a-4a1f-8d47-3062d48eeb7b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5b7cd8d8-4d3a-4a1f-8d47-3062d48eeb7b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5b7cd8d8-4d3a-4a1f-8d47-3062d48eeb7b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d71cc681-9212-494d-96fc-6c2923f28932\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d71cc681-9212-494d-96fc-6c2923f28932')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d71cc681-9212-494d-96fc-6c2923f28932 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_9a9d788b-4167-4209-80bf-d3f716b527f4\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_9a9d788b-4167-4209-80bf-d3f716b527f4 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 3000,\n  \"fields\": [\n    {\n      \"column\": \"longitude\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.9949362939550161,\n        \"min\": -124.18,\n        \"max\": -114.49,\n        \"num_unique_values\": 607,\n        \"samples\": [\n          -121.15,\n          -121.46,\n          -121.02\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"latitude\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.1296695233438325,\n        \"min\": 32.56,\n        \"max\": 41.92,\n        \"num_unique_values\": 587,\n        \"samples\": [\n          40.17,\n          33.69,\n          39.61\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"housing_median_age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12.555395554955755,\n        \"min\": 1.0,\n        \"max\": 52.0,\n        \"num_unique_values\": 52,\n        \"samples\": [\n          14.0,\n          49.0,\n          7.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_rooms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2155.59333162558,\n        \"min\": 6.0,\n        \"max\": 30450.0,\n        \"num_unique_values\": 2215,\n        \"samples\": [\n          1961.0,\n          1807.0,\n          680.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_bedrooms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 415.6543681363232,\n        \"min\": 2.0,\n        \"max\": 5419.0,\n        \"num_unique_values\": 1055,\n        \"samples\": [\n          532.0,\n          764.0,\n          2162.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"population\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1030.5430124122422,\n        \"min\": 5.0,\n        \"max\": 11935.0,\n        \"num_unique_values\": 1802,\n        \"samples\": [\n          947.0,\n          1140.0,\n          2019.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"households\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 365.42270980552604,\n        \"min\": 2.0,\n        \"max\": 4930.0,\n        \"num_unique_values\": 1026,\n        \"samples\": [\n          646.0,\n          629.0,\n          504.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"median_income\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.854511729691481,\n        \"min\": 0.4999,\n        \"max\": 15.0001,\n        \"num_unique_values\": 2578,\n        \"samples\": [\n          1.725,\n          0.7403,\n          2.6964\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"median_house_value\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 113119.68746964433,\n        \"min\": 22500.0,\n        \"max\": 500001.0,\n        \"num_unique_values\": 1784,\n        \"samples\": [\n          71900.0,\n          63000.0,\n          115800.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KL4o22EYWyU2"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}